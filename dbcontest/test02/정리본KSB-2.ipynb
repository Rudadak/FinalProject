{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c39694",
   "metadata": {},
   "source": [
    "# library loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b16de6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-31T05:05:39.348767Z",
     "start_time": "2023-01-31T05:05:30.361678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "#!pip install ko-sentence-transformers \n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from ko_sentence_transformers.models import KoBertTransformer\n",
    "\n",
    "# Model loading\n",
    "word_embedding_model = KoBertTransformer(\"monologg/kobert\", max_seq_length=75)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode='mean')\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "\n",
    "# embedder loading\n",
    "embedder = SentenceTransformer(\"jhgan/ko-sbert-sts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba2b74",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754b52e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-31T05:05:39.766110Z",
     "start_time": "2023-01-31T05:05:39.662686Z"
    }
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('DBdata.csv')  # ê²½ë¡œ ìˆ˜ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a97b457",
   "metadata": {},
   "source": [
    "# ê¸°ë³¸ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e3cdd3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-31T05:16:46.330607Z",
     "start_time": "2023-01-31T05:05:41.124596Z"
    }
   },
   "outputs": [],
   "source": [
    "# ì „ì²´ ì¹´í…Œê³ ë¦¬(tot)\n",
    "## corpus\n",
    "texts = ''\n",
    "for line in df.rv[:]:\n",
    "    texts = texts + line\n",
    "text = list(filter(None, texts.split(sep='\\n')))\n",
    "## embedding\n",
    "tot_corpus = text\n",
    "tot_embedding = embedder.encode(tot_corpus, convert_to_tensor = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68208d6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-31T05:28:18.716279Z",
     "start_time": "2023-01-31T05:16:46.332602Z"
    }
   },
   "outputs": [],
   "source": [
    "# ê¸°ì´ˆì¼€ì–´ ì¹´í…Œê³ ë¦¬(bas)\n",
    "## ë²”ìœ„ split\n",
    "fir = df[df['cate'] == 'í† ë„ˆ'].index[0]\n",
    "las = df[df['cate'] == 'ë¯¸ìŠ¤íŠ¸'].index[-1]\n",
    "## corpus\n",
    "texts = ''\n",
    "for line in df.rv[fir:las]:\n",
    "    texts = texts + line\n",
    "text = list(filter(None, texts.split(sep='\\n')))\n",
    "\n",
    "## embedding\n",
    "bas_corpus = text\n",
    "bas_embedding = embedder.encode(bas_corpus, convert_to_tensor = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b81c73b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-31T05:39:49.340589Z",
     "start_time": "2023-01-31T05:28:18.718022Z"
    }
   },
   "outputs": [],
   "source": [
    "# ìƒ‰ì¡°ì¼€ì–´ ì¹´í…Œê³ ë¦¬(col)\n",
    "## ë²”ìœ„ split\n",
    "fir = df[df['cate'] == 'ë¦½'].index[0]\n",
    "las = df[df['cate'] == 'ì•„ì´'].index[-1]\n",
    "## corpus\n",
    "texts = ''\n",
    "for line in df.rv[fir:las]:\n",
    "    texts = texts + line\n",
    "text = list(filter(None, texts.split(sep='\\n')))\n",
    "\n",
    "## embedding\n",
    "col_corpus = text\n",
    "col_embedding = embedder.encode(col_corpus, convert_to_tensor = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae227cf",
   "metadata": {},
   "source": [
    "# í•„ìš”í•œ ì‘ì—… ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9c1036c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-31T05:46:34.894568Z",
     "start_time": "2023-01-31T05:46:34.870637Z"
    }
   },
   "outputs": [],
   "source": [
    "# ì¶œë ¥í¼ í•¨ìˆ˜\n",
    "def menu():\n",
    "    print('-'*30)\n",
    "    print('â˜…ì›í•˜ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”â˜…')\n",
    "    print('1. ì „ì²´')\n",
    "    print('2. ê¸°ì´ˆ')\n",
    "    print('3. ìƒ‰ì¡°')\n",
    "    print('-'*30)\n",
    "    embed, corpus, cate = choice_cate()\n",
    "    return embed, corpus, cate \n",
    "    \n",
    "    \n",
    "# ì¹´í…Œê³ ë¦¬ ì„ íƒ í•¨ìˆ˜\n",
    "def choice_cate():\n",
    "    num = int(input('â†’ '))\n",
    "    if num == 1:\n",
    "        embed = tot_embedding\n",
    "        corpus = tot_corpus\n",
    "        cate = 'ì „ì²´'\n",
    "    elif num == 2:\n",
    "        embed = bas_embedding\n",
    "        corpus = bas_corpus\n",
    "        cate = 'ê¸°ì´ˆ'\n",
    "    elif num == 3:\n",
    "        embed = col_embedding\n",
    "        corpus = col_corpus\n",
    "        cate = 'ìƒ‰ì¡°'\n",
    "    else:\n",
    "        print('ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1~3 ì‚¬ì´ì˜ ìˆ«ìë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.')\n",
    "        return menu()\n",
    "    return embed, corpus, cate\n",
    "        \n",
    "\n",
    "# ìœ ì‚¬ ë¬¸ì¥ ë¦¬í„´í•¨ìˆ˜\n",
    "def num_return(query, embed, corpus, cate):\n",
    "\n",
    "    cate_embedding = embed\n",
    "    # ìœ ì‚¬ë„ í‰ê°€ë¥¼ ìœ„í•œ ì‘ì—…\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, cate_embedding)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "    # ìƒìœ„ ê²°ê³¼ ì¶”ì¶œ\n",
    "    top_results = np.argpartition(-cos_scores, range(5))[0:5]\n",
    "    print(\"\\nâ–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½\\n\")\n",
    "    print(\"ìš”ì²­ ë¬¸ì¥:\", query)\n",
    "    print(f\"ğŸŒ¼{cate} ì¹´í…Œê³ ë¦¬ì˜ ë¦¬ë·°ë“¤ ì¤‘ ê°€ì¥ ìœ ì‚¬í•œ 5ê°œ ë¦¬ë·°ë¬¸ì¥ğŸŒ¼\\n\")\n",
    "    for v, idx in enumerate(top_results[0:5]):\n",
    "        text = corpus[idx].strip() \n",
    "        for i in range(3344):\n",
    "            if text in df['rv'][i]:\n",
    "                pname = df['pname'][i]\n",
    "        print(v+1, pname, '\\n','â–¶',text, \"(Score: %.4f)\" % (cos_scores[idx]))\n",
    "    print(\"\\nâ–³â–³â–³â–³â–³â–³â–³â–³â–³â–³â–³â–³â–³â–³â–³â–³â–³â–³\\n\")\n",
    "\n",
    "        \n",
    "        \n",
    "def play_rv():\n",
    "    query= str(input('ê²€ìƒ‰í•˜ê¸° : '))\n",
    "    embed, corpus, cate = menu()\n",
    "    num_return(query, embed, corpus, cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9d6ed03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-31T06:01:22.301523Z",
     "start_time": "2023-01-31T06:01:14.189224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²€ìƒ‰í•˜ê¸° : ì¥ë¯¸í–¥ ìˆ˜ë¶„í¬ë¦¼\n",
      "------------------------------\n",
      "â˜…ì›í•˜ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”â˜…\n",
      "1. ì „ì²´\n",
      "2. ê¸°ì´ˆ\n",
      "3. ìƒ‰ì¡°\n",
      "------------------------------\n",
      "â†’ 1\n",
      "\n",
      "â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½â–½\n",
      "\n",
      "ìš”ì²­ ë¬¸ì¥: ì¥ë¯¸í–¥ ìˆ˜ë¶„í¬ë¦¼\n",
      "â–¶ì „ì²´ì¹´í…Œê³ ë¦¬ì˜ ë¦¬ë·°ë“¤ ì¤‘ ê°€ì¥ ìœ ì‚¬í•œ 5ê°œ ë¦¬ë·°ë¬¸ì¥â—€\n",
      "\n",
      "0 ì—ìŠ¤íŠ¸ë¼ ì•„í† ë² ë¦¬ì–´365 í¬ë¦¼ ê¸°í”„íŠ¸ ì„¸íŠ¸(í¬ë¦¼ 80ml*2+ë¡œì…˜ 60ml+í•˜ì´ë“œë¡œì—ì„¼ìŠ¤ 40ml) \n",
      " â–¶ ğŸ€ ì´‰ì´‰í•œ íƒ€ì…ì˜ ìˆ˜ë¶„ ì—ì„¼ìŠ¤ (Score: 0.7792)\n",
      "1 ë¹„ìš˜ë“œ ì—”ì ¤ì•„ì¿ ì•„ ìˆ˜ë¶„ ì§„ì • í¬ë¦¼ 150ml 1+1 ê¸°íš (ë¹„ê±´) \n",
      " â–¶ ë”± ìˆ˜ë¶„ì„ ì±„ì›Œì£¼ëŠ” ìˆœí•œ ìˆ˜ë¶„í¬ë¦¼ì´ê¸° ë•Œë¬¸ì— (Score: 0.7633)\n",
      "2 [ë©”ì´í¬ì—…ì•„í‹°ìŠ¤íŠ¸Pick] ì—ìŠ¤í…Œë¤ ì…€ë£°ëŸ¬ ì›Œí„° ë¯¸ìŠ¤íŠ¸ 200ml (í•­ì‚°í™” ë¯¸ìŠ¤íŠ¸) \n",
      " â–¶ ì—ìŠ¤í…Œë¤ ì…€ë£°ëŸ¬ ì›Œí„° ë¯¸ìŠ¤íŠ¸ëŠ” ì´‰ì´‰í•¨ì´ ì˜ ìœ ì§€ ë˜ëŠ”ê²ƒ ê°™ë„¤ìš”. (Score: 0.7571)\n",
      "3 [ë©”ì´í¬ì—…ì•„í‹°ìŠ¤íŠ¸Pick] ì—ìŠ¤í…Œë¤ ì…€ë£°ëŸ¬ ì›Œí„° ë¯¸ìŠ¤íŠ¸ 200ml (í•­ì‚°í™” ë¯¸ìŠ¤íŠ¸) \n",
      " â–¶ ë¬¼ë¯¸ìŠ¤íŠ¸ì¸ë° ì´‰ì´‰í•˜êµ¬ ë³´ìŠµë ¥ ì¢‹ì•„ìš” (Score: 0.7491)\n",
      "4 [ë‹¨ë…ê¸°íš] í† ë¦¬ë“  ë‹¤ì´ë¸Œì¸ ì €ë¶„ì íˆì•Œë£¨ë¡ ì‚° ìˆ˜ë”©í¬ë¦¼ ë”ë¸”ê¸°íš(100ml+100ml) \n",
      " â–¶ ì´ ì œí’ˆì€ ìˆ˜ë¶„í¬ë¦¼ì˜ ì •ì„ ê°™ì•„ìš”ğŸ˜€ (Score: 0.7448)\n"
     ]
    }
   ],
   "source": [
    "play_rv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1cb10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
